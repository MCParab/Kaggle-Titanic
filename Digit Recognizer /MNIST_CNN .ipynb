{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "import numpy as np \n",
    "import math \n",
    "import matplotlib.pyplot as plt \n",
    "import pandas as pd \n",
    "from tensorflow.contrib.learn.python.learn.datasets.mnist import read_data_sets\n",
    "tf.set_random_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read in training data from train.csv \n",
    "dftrain = pd.read_csv('Data/train.csv')\n",
    "dftrainFeatureVector = dftrain.drop(['label'], axis=1)\n",
    "trainFeatureVector = dftrainFeatureVector.values.astype(dtype = np.float32)\n",
    "trainFeatureVectorConvoFormat = trainFeatureVector.reshape(42000, 28, 28, 1)\n",
    "\n",
    "trainLabelsList = dftrain['label'].tolist()\n",
    "ohtrainLabelTensor = tf.one_hot(trainLabelsList, depth=10)\n",
    "ohtrainLabelNdarray = tf.Session().run(ohtrainLabelTensor).astype(dtype = np.float64)\n",
    "\n",
    "# Read in testing data from test.csv \n",
    "dftest = pd.read_csv('Data/test.csv')\n",
    "testFeatureVector = dftest.values.astype(dtype = np.float32)\n",
    "testFeatureVectorConvoFormat = testFeatureVector.reshape(28000, 28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 28, 28, 1)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainFeatureVectorConvoFormat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe4fc06f748>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Displaying from csv data \n",
    "pixels = testFeatureVectorConvoFormat[0].reshape((28,28))\n",
    "plt.imshow(pixels, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Construct tensorflow graph \n",
    "\n",
    "# Define tensorflow graph \n",
    "X = tf.placeholder(tf.float32, [None, 28, 28, 1])\n",
    "Y_ = tf.placeholder(tf.float32, [None, 10])\n",
    "lr = tf.placeholder(tf.float32)\n",
    "pkeep = tf.placeholder(tf.float32)\n",
    "\n",
    "K = 6 \n",
    "L = 12\n",
    "M = 24\n",
    "N = 200 \n",
    "\n",
    "\n",
    "W1 = tf.Variable(tf.truncated_normal([6, 6, 1, K], stddev=0.1))  # 6x6 patch, 1 input channel, K output channels\n",
    "B1 = tf.Variable(tf.constant(0.1, tf.float32, [K]))\n",
    "W2 = tf.Variable(tf.truncated_normal([5, 5, K, L], stddev=0.1))\n",
    "B2 = tf.Variable(tf.constant(0.1, tf.float32, [L]))\n",
    "W3 = tf.Variable(tf.truncated_normal([4, 4, L, M], stddev=0.1))\n",
    "B3 = tf.Variable(tf.constant(0.1, tf.float32, [M]))\n",
    "\n",
    "W4 = tf.Variable(tf.truncated_normal([7 * 7 * M, N], stddev=0.1))\n",
    "B4 = tf.Variable(tf.constant(0.1, tf.float32, [N]))\n",
    "\n",
    "W5 = tf.Variable(tf.truncated_normal([N, 10], stddev=0.1))\n",
    "B5 = tf.Variable(tf.constant(0.1, tf.float32, [10]))\n",
    "\n",
    "# The model\n",
    "stride = 1  # output is 28x28\n",
    "Y1 = tf.nn.relu(tf.nn.conv2d(X, W1, strides=[1, stride, stride, 1], padding='SAME') + B1)\n",
    "stride = 2  # output is 14x14\n",
    "Y2 = tf.nn.relu(tf.nn.conv2d(Y1, W2, strides=[1, stride, stride, 1], padding='SAME') + B2)\n",
    "stride = 2  # output is 7x7\n",
    "Y3 = tf.nn.relu(tf.nn.conv2d(Y2, W3, strides=[1, stride, stride, 1], padding='SAME') + B3)\n",
    "\n",
    "# reshape the output from the third convolution for the fully connected layer\n",
    "YY = tf.reshape(Y3, shape=[-1, 7 * 7 * M])\n",
    "\n",
    "Y4 = tf.nn.relu(tf.matmul(YY, W4) + B4)\n",
    "YY4 = tf.nn.dropout(Y4, pkeep)\n",
    "Ylogits = tf.matmul(YY4, W5) + B5\n",
    "Y = tf.nn.softmax(Ylogits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits=Ylogits, labels=Y_)\n",
    "cross_entropy = tf.reduce_mean(cross_entropy)*100\n",
    "\n",
    "# accuracy of the trained model, between 0 (worst) and 1 (best)\n",
    "correct_prediction = tf.equal(tf.argmax(Y, 1), tf.argmax(Y_, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "predictions = tf.argmax(Y, 1)\n",
    "\n",
    "# training step, the learning rate is a placeholder\n",
    "train_step = tf.train.AdamOptimizer(lr).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: training accuracy:0.08 training loss: 10016.8 (lr:0.003)\n",
      "0: ********* test accuracy:0.0741 test loss: 10146.0\n",
      "100: training accuracy:0.93 training loss: 31.3368 (lr:0.0028585653310520707)\n",
      "200: training accuracy:0.94 training loss: 24.7336 (lr:0.0027240285123042826)\n",
      "300: training accuracy:0.95 training loss: 19.0238 (lr:0.0025960531316326675)\n",
      "400: training accuracy:0.92 training loss: 32.0617 (lr:0.0024743191839261473)\n",
      "500: training accuracy:0.94 training loss: 17.9723 (lr:0.002358522270907074)\n",
      "500: ********* test accuracy:0.9709 test loss: 9.05\n",
      "600: training accuracy:0.99 training loss: 4.24289 (lr:0.002248372839976982)\n",
      "700: training accuracy:0.94 training loss: 18.5875 (lr:0.002143595460184269)\n",
      "800: training accuracy:0.99 training loss: 4.87345 (lr:0.002043928133503354)\n",
      "900: training accuracy:0.98 training loss: 3.67689 (lr:0.001949121639703143)\n",
      "1000: training accuracy:1.0 training loss: 1.73464 (lr:0.0018589389131666372)\n",
      "1000: ********* test accuracy:0.984 test loss: 4.82439\n",
      "1100: training accuracy:0.98 training loss: 2.62321 (lr:0.0017731544501034114)\n",
      "1200: training accuracy:0.99 training loss: 4.31089 (lr:0.0016915537446726768)\n",
      "1300: training accuracy:0.98 training loss: 6.12255 (lr:0.0016139327526069466)\n",
      "1400: training accuracy:0.99 training loss: 3.51322 (lr:0.0015400973809950877)\n",
      "1500: training accuracy:0.99 training loss: 2.5653 (lr:0.0014698630029489428)\n",
      "1500: ********* test accuracy:0.9868 test loss: 3.93013\n",
      "1600: training accuracy:1.0 training loss: 1.40809 (lr:0.0014030539959399427)\n",
      "1700: training accuracy:1.0 training loss: 0.471347 (lr:0.0013395033026513076)\n",
      "1800: training accuracy:1.0 training loss: 0.900001 (lr:0.0012790520132477375)\n",
      "1900: training accuracy:1.0 training loss: 0.892182 (lr:0.0012215489680180538)\n",
      "2000: training accuracy:0.98 training loss: 5.02673 (lr:0.0011668503793971828)\n",
      "2000: ********* test accuracy:0.9925 test loss: 2.3866\n",
      "2100: training accuracy:0.99 training loss: 2.48215 (lr:0.0011148194724223506)\n",
      "2200: training accuracy:0.99 training loss: 1.10458 (lr:0.0010653261427244307)\n",
      "2300: training accuracy:0.99 training loss: 1.005 (lr:0.0010182466311992545)\n",
      "2400: training accuracy:1.0 training loss: 0.97972 (lr:0.0009734632145453863)\n",
      "2500: training accuracy:0.98 training loss: 2.70632 (lr:0.0009308639108945514)\n",
      "2500: ********* test accuracy:0.9978 test loss: 0.813958\n",
      "2600: training accuracy:1.0 training loss: 0.567528 (lr:0.0008903421997986366)\n",
      "2700: training accuracy:1.0 training loss: 0.114782 (lr:0.0008517967558730855)\n",
      "2800: training accuracy:1.0 training loss: 0.541611 (lr:0.0008151311954306589)\n",
      "2900: training accuracy:1.0 training loss: 0.504988 (lr:0.0007802538354720133)\n",
      "3000: training accuracy:1.0 training loss: 0.718262 (lr:0.0007470774644304465)\n",
      "3000: ********* test accuracy:0.9985 test loss: 0.585919\n"
     ]
    }
   ],
   "source": [
    "# init\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "def getBatch(i, size, trainFeatures, trainLabels):\n",
    "    startIndex = (i * size) % 42000\n",
    "    endIndex = startIndex + size\n",
    "    batch_X = trainFeatures[startIndex : endIndex]\n",
    "    batch_Y = trainLabels[startIndex : endIndex]\n",
    "    return batch_X, batch_Y\n",
    "\n",
    "# You can call this function in a loop to train the model, 100 images at a time\n",
    "def training_step(i):\n",
    "\n",
    "    # training on batches of 100 images with 100 labels\n",
    "    size = 100\n",
    "    batch_X, batch_Y = getBatch(i, size, trainFeatureVectorConvoFormat, ohtrainLabelNdarray)\n",
    "\n",
    "    # learning rate decay\n",
    "    max_learning_rate = 0.003\n",
    "    min_learning_rate = 0.0001\n",
    "    decay_speed = 2000.0\n",
    "    learning_rate = min_learning_rate + (max_learning_rate - min_learning_rate) * math.exp(-i/decay_speed)\n",
    "\n",
    "    # compute training values\n",
    "    if i % 100 == 0:\n",
    "        '''\n",
    "        When we sess.run here, we are calculating the accuracy and cross_entropy of the model on batch_X and batch_Y (ie. on 100 pieces of data)\n",
    "        '''\n",
    "        a, c = sess.run([accuracy, cross_entropy], {X: batch_X, Y_: batch_Y, pkeep: 1.0})\n",
    "        print(str(i) + \": training accuracy:\" + str(a) + \" training loss: \" + str(c) + \" (lr:\" + str(learning_rate) + \")\")\n",
    "\n",
    "    # compute test values\n",
    "    if i % 500 == 0:\n",
    "        '''\n",
    "        When we sess.run here, we are calculating the accuracy and cross_entropy of the model on all of the data\n",
    "        '''\n",
    "        a, c = sess.run([accuracy, cross_entropy], {X: trainFeatureVectorConvoFormat[-10000:], Y_: ohtrainLabelNdarray[-10000:], pkeep: 1.0})\n",
    "        print(str(i) + \": ********* test accuracy:\" + str(a) + \" test loss: \" + str(c))\n",
    "\n",
    "    # the backpropagation training step\n",
    "    sess.run(train_step, {X: batch_X, Y_: batch_Y, lr: learning_rate, pkeep: 0.75})\n",
    "\n",
    "# Run number of iterations training the NN    \n",
    "for i in range(10000+1): \n",
    "    training_step(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Print the test accurscy on some data that was held out\n",
    "a, c = sess.run([accuracy, cross_entropy], {X: trainFeatureVectorConvoFormat[-10000:], Y_: ohtrainLabelNdarray[-10000:], pkeep: 1.0})\n",
    "print(\"\\n ********* test accuracy:\" + str(a) + \" test loss: \" + str(c))\n",
    "\n",
    "# Get predictions on test data\n",
    "p = sess.run([predictions], {X: testFeatureVectorConvoFormat, pkeep: 1.0})\n",
    "\n",
    "# Write predictions to csv file\n",
    "results = pd.DataFrame({'ImageId': pd.Series(range(1, len(p[0]) + 1)), 'Label': pd.Series(p[0])})\n",
    "results.to_csv('results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:car-behavioral-cloning]",
   "language": "python",
   "name": "conda-env-car-behavioral-cloning-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
